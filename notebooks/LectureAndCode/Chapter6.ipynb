{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3367341",
   "metadata": {},
   "source": [
    "# Improving the log analyzer\n",
    "\n",
    "Enhancing our second CLI application so that it can analyze multiple files in multiple formats and use JSON configuration instead of hard-coded values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67926912",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Objective\n",
    "\n",
    "To understand what is **JSON** and how to use it and another helpful module **pprint**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dce56e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## JSON\n",
    "\n",
    "[`json`](https://docs.python.org/3/library/json.html#module-json) exposes an API familiar to users of the standard library [`marshal`](https://docs.python.org/3/library/marshal.html#module-marshal) and [`pickle`](https://docs.python.org/3/library/pickle.html#module-pickle) modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be299b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### xml.etree.ElementTree\n",
    "\n",
    "The [`xml.etree.ElementTree`](https://docs.python.org/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree) module implements a simple and efficient API for parsing and creating XML data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341edf08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## pprint\n",
    "\n",
    "The [`pprint`](https://docs.python.org/3.9/library/pprint.html?highlight=pprint#module-pprint) module provides a capability to “pretty-print” arbitrary Python data structures in a form which can be used as input to the interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53cb1f-9ba3-472e-9c4f-b942c20a84fc",
   "metadata": {},
   "source": [
    "## Hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519f8f30-1901-4885-97f8-becb191409c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-e] [-r RECURSIVE] [-o] [-H]\n",
      "                             search input_paths [input_paths ...]\n",
      "ipykernel_launcher.py: error: the following arguments are required: input_paths\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/virtualenvs/python3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import colorama\n",
    "\n",
    "\n",
    "class Grep:\n",
    "    def __init__(self, is_regex=False, only_matching=False, with_filename=False):\n",
    "        self._is_regex = is_regex\n",
    "        self._only_matching = only_matching\n",
    "        self._with_filename = with_filename\n",
    "\n",
    "    def search_in_string(self, search, search_string, return_groups=False):\n",
    "        search_result = None\n",
    "        search_groups = None\n",
    "        if self._is_regex:\n",
    "            search_result = re.search(search, search_string)\n",
    "            if search_result:\n",
    "                # if search_result := re.search(search, search_string):\n",
    "                search_groups = search_result.groupdict()\n",
    "                search_result = search_string[search_result.span()[0]:search_result.span()[1]] \\\n",
    "                    if self._only_matching else search_string\n",
    "        elif not self._is_regex and search_string.find(search) >= 0:\n",
    "            search_result = search_string\n",
    "        if return_groups:\n",
    "            return (search_result, search_groups)\n",
    "        else:\n",
    "            return search_result\n",
    "\n",
    "    def search_in_path(self, search, input_path):\n",
    "        search_results = []\n",
    "        if os.path.isdir(input_path):\n",
    "            print('Scanning path: {:25s}'.format(input_path))\n",
    "            input_dir_contents = os.scandir(path=input_path)\n",
    "            for input_dir_element in input_dir_contents:\n",
    "                search_results.extend(self.search_in_path(search, input_dir_element.path))\n",
    "        else:\n",
    "            input_file = open(input_path, 'r')\n",
    "            print('Opening file: {:25s}'.format(input_file.name))\n",
    "            for input_line in input_file.readlines():\n",
    "                search_result = self.search_in_string(search, input_line)\n",
    "                if search_result:\n",
    "                    search_results.append('{}: {}'.format(os.path.basename(input_file.name), search_result) \\\n",
    "                                              if self._with_filename else search_result)\n",
    "        return search_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('search', type=str, help='Pattern to search for')\n",
    "    parser.add_argument('input_paths', nargs='+', type=str, help='List of input file paths')\n",
    "    parser.add_argument('-e', '--regex', dest='is_regexp', action='store_true', help='Use search as regexp')\n",
    "    parser.add_argument('-r', '--recursive', type=str, help='Search recursively in directories')\n",
    "    parser.add_argument('-o', '--only-matching', dest='only_matching', action='store_true',\n",
    "                        help='Show matched string only')\n",
    "    parser.add_argument('-H', '--with-filename', dest='with_filename', action='store_true',\n",
    "                        help='Show matched string only')\n",
    "    args = parser.parse_args(sys.argv[1:])\n",
    "\n",
    "    grep = Grep(args.is_regexp, args.only_matching, args.with_filename)\n",
    "    for input_path in args.input_paths:\n",
    "        search_results = grep.search_in_path(args.search, input_path)\n",
    "        print(colorama.Style.RESET_ALL + 'Search results:')\n",
    "        for search_result in search_results:\n",
    "            print(colorama.Fore.GREEN + search_result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8240c99c-33e2-4843-8c55-55157acd1484",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40748/1780979739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolorama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChapter5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0megrep\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0megrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Code'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pprint\n",
    "import Code.Chapter5.egrep as egrep\n",
    "\n",
    "\n",
    "def filter_by_source(source, watched_entries):\n",
    "    for entry_match, entry_meta in watched_entries:\n",
    "        if entry_meta['source'] == source:\n",
    "            yield {'match': entry_match, 'meta': entry_meta}\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" 6.1 Scan multiple files \"\"\"\n",
    "    # grep = egrep.Grep(is_regex=True, with_filename=False, only_matching=True)\n",
    "    # files_to_scan = [\"test_data/syslog\", \"test_data/syslog2\"]\n",
    "    # events = {}\n",
    "    # for scanned_file in files_to_scan:\n",
    "    #     input_file_lines = open(scanned_file, 'r').readlines()\n",
    "    #     watched_entries = []\n",
    "    #     for input_line in input_file_lines:\n",
    "    #         search_result, search_groups = grep.search_in_string(\n",
    "    #             \"^\\w+\\W+\\d+\\W+(?P<time>\\d{2}:\\d{2}:\\d{2})\\W+\\w+\\W+\\w+\\W+(?P<source>[\\w\\-]+):\", input_line, True)\n",
    "    #         if search_result:\n",
    "    #             watched_entries.append((search_result, search_groups))\n",
    "    #     sources = (entry_meta['source'] for entry_match, entry_meta in watched_entries)\n",
    "    #     for source in set(sources):\n",
    "    #         events_per_source = filter_by_source(source, watched_entries)\n",
    "    #         times = [datetime.datetime.strptime('2020-10-10 ' + event['meta']['time'], '%Y-%m-%d %H:%M:%S')\n",
    "    #                  for event in events_per_source]\n",
    "    #         if source in events:\n",
    "    #             times.append(events[source]['min'])\n",
    "    #             times.append(events[source]['max'])\n",
    "    #         events[source] = {'min': min(times), 'max': max(times)}\n",
    "\n",
    "    \"\"\" 6.2 Scan config from JSON \"\"\"\n",
    "    # grep = egrep.Grep(is_regex=True, with_filename=False, only_matching=True)\n",
    "    # config = json.load(open('config.json', 'r'))\n",
    "    # pprint.pprint(config)\n",
    "    # events = {}\n",
    "    # for scanned_file in config['files_to_scan']:\n",
    "    #     input_file_lines = open(scanned_file, 'r').readlines()\n",
    "    #     watched_entries = []\n",
    "    #     for input_line in input_file_lines:\n",
    "    #         for search_pattern in config['search_patterns']:\n",
    "    #             search_result, search_groups = grep.search_in_string(search_pattern, input_line, True)\n",
    "    #             if search_result:\n",
    "    #                 watched_entries.append((search_result, search_groups))\n",
    "    #     sources = (entry_meta['source'] for entry_match, entry_meta in watched_entries)\n",
    "    #     for source in set(sources):\n",
    "    #         events_per_source = filter_by_source(source, watched_entries)\n",
    "    #         times = [datetime.datetime.strptime(event['meta']['time'], '%Y%m%d %H:%M:%S')\n",
    "    #                  for event in events_per_source]\n",
    "    #         if source in events:\n",
    "    #             times.append(events[source]['min'])\n",
    "    #             times.append(events[source]['max'])\n",
    "    #         events[source] = {'min': min(times), 'max': max(times)}\n",
    "\n",
    "    \"\"\" 6.3 Scan config from more complex JSON (alternative would be date time group capturing) \"\"\"\n",
    "    grep = egrep.Grep(is_regex=True, with_filename=False, only_matching=True)\n",
    "    config = json.load(open('config2.json', 'r'))\n",
    "    pprint.pprint(config)\n",
    "    events = {}\n",
    "    for scanned_file in config['files_to_scan']:\n",
    "        input_file_lines = open(scanned_file, 'r').readlines()\n",
    "        for search_config in config['search_config']:\n",
    "            watched_entries = []\n",
    "            for input_line in input_file_lines:\n",
    "                search_result, search_groups = grep.search_in_string(search_config['search_pattern'], input_line, True)\n",
    "                if search_result:\n",
    "                    watched_entries.append((search_result, search_groups))\n",
    "            sources = (entry_meta['source'] for entry_match, entry_meta in watched_entries)\n",
    "            for source in set(sources):\n",
    "                events_per_source = filter_by_source(source, watched_entries)\n",
    "                times = [datetime.datetime.strptime(event['meta']['time'], search_config['date_pattern'])\n",
    "                         for event in events_per_source]\n",
    "                if source in events:\n",
    "                    times.append(events[source]['min'])\n",
    "                    times.append(events[source]['max'])\n",
    "                events[source] = {'min': min(times), 'max': max(times)}\n",
    "\n",
    "    \"\"\" Show pprint \"\"\"\n",
    "    pprint.pprint(events)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552a232-6fb7-480c-964f-ad09fb0522f8",
   "metadata": {},
   "source": [
    "[Previous chapter - Chapter5](Chapter5.ipynb) | [Next chapter - Chapter7](Chapter7.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
